{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cjm-transcription-plugin-voxtral-vllm\n",
    "\n",
    "> Mistral Voxtral plugin for the cjm-transcription-plugin-system library - provides local speech-to-text transcription through vLLM with configurable model selection and parameter control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "```bash\n",
    "pip install cjm_transcription_plugin_voxtral_vllm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Structure\n",
    "\n",
    "```\n",
    "nbs/\n",
    "└── plugin.ipynb # Plugin implementation for Mistral Voxtral transcription through vLLM server\n",
    "```\n",
    "\n",
    "Total: 1 notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Dependencies\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    plugin[plugin<br/>Voxtral VLLM Plugin]\n",
    "\n",
    "```\n",
    "\n",
    "No cross-module dependencies detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLI Reference\n",
    "\n",
    "No CLI commands found in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Overview\n",
    "\n",
    "Detailed documentation for each module in the project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxtral VLLM Plugin (`plugin.ipynb`)\n",
    "> Plugin implementation for Mistral Voxtral transcription through vLLM server\n",
    "\n",
    "#### Import\n",
    "\n",
    "```python\n",
    "from cjm_transcription_plugin_voxtral_vllm.plugin import (\n",
    "    VLLMServer,\n",
    "    VoxtralVLLMPlugin\n",
    ")\n",
    "```\n",
    "\n",
    "#### Functions\n",
    "\n",
    "```python\n",
    "@patch\n",
    "def supports_streaming(\n",
    "    self: VoxtralVLLMPlugin\n",
    ") -> bool\n",
    "    \"Check if this plugin supports streaming transcription.\"\n",
    "```\n",
    "\n",
    "```python\n",
    "@patch\n",
    "def execute_stream(\n",
    "    self: VoxtralVLLMPlugin,\n",
    "    audio: Union[AudioData, str, Path],  # Audio data or path to audio file\n",
    "    **kwargs  # Additional plugin-specific parameters\n",
    ") -> Generator[str, None, TranscriptionResult]:  # Yields text chunks, returns final result\n",
    "    \"\"\"\n",
    "    Stream transcription results chunk by chunk.\n",
    "    \n",
    "    Args:\n",
    "        audio: Audio data or path to audio file\n",
    "        **kwargs: Additional plugin-specific parameters\n",
    "        \n",
    "    Yields:\n",
    "        str: Partial transcription text chunks as they become available\n",
    "        \n",
    "    Returns:\n",
    "        TranscriptionResult: Final complete transcription with metadata\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "#### Classes\n",
    "\n",
    "```python\n",
    "class VLLMServer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str = \"mistralai/Voxtral-Mini-3B-2507\",\n",
    "        port: int = 8000,\n",
    "        host: str = \"0.0.0.0\",\n",
    "        gpu_memory_utilization: float = 0.85,\n",
    "        log_level: str = \"INFO\",  # DEBUG, INFO, WARNING, ERROR\n",
    "        capture_logs: bool = True,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            model: str = \"mistralai/Voxtral-Mini-3B-2507\",\n",
    "            port: int = 8000,\n",
    "            host: str = \"0.0.0.0\",\n",
    "            gpu_memory_utilization: float = 0.85,\n",
    "            log_level: str = \"INFO\",  # DEBUG, INFO, WARNING, ERROR\n",
    "            capture_logs: bool = True,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    def add_log_callback(self, callback: Callable[[str], None]):\n",
    "            \"\"\"Add a callback function that will be called for each log line.\n",
    "            \n",
    "            Args:\n",
    "                callback: Function that takes a log line string as input\n",
    "            \"\"\"\n",
    "            self.log_callbacks.append(callback)\n",
    "        \n",
    "        def _process_log_line(self, line: str)\n",
    "        \"Add a callback function that will be called for each log line.\n",
    "\n",
    "Args:\n",
    "    callback: Function that takes a log line string as input\"\n",
    "    \n",
    "    def start(self, wait_for_ready: bool = True, timeout: int = 120, show_progress: bool = True):\n",
    "            \"\"\"Start the vLLM server.\n",
    "            \n",
    "            Args:\n",
    "                wait_for_ready: Wait for server to be ready before returning\n",
    "                timeout: Maximum time to wait for server to be ready\n",
    "                show_progress: Show progress indicators during startup\n",
    "            \"\"\"\n",
    "            if self.is_running()\n",
    "        \"Start the vLLM server.\n",
    "\n",
    "Args:\n",
    "    wait_for_ready: Wait for server to be ready before returning\n",
    "    timeout: Maximum time to wait for server to be ready\n",
    "    show_progress: Show progress indicators during startup\"\n",
    "    \n",
    "    def stop(self):\n",
    "            \"\"\"Stop the vLLM server.\"\"\"\n",
    "            if self.process and self.process.poll() is None\n",
    "        \"Stop the vLLM server.\"\n",
    "    \n",
    "    def restart(self):\n",
    "            \"\"\"Restart the server.\"\"\"\n",
    "            self.stop()\n",
    "            time.sleep(2)\n",
    "            self.start()\n",
    "        \n",
    "        def is_running(self) -> bool\n",
    "        \"Restart the server.\"\n",
    "    \n",
    "    def is_running(self) -> bool\n",
    "        \"Check if server is running and responsive.\n",
    "\n",
    "This method checks both if the process is alive and if the server\n",
    "is actually responding to health checks.\"\n",
    "    \n",
    "    def get_recent_logs(self, n: int = 100) -> List[str]:\n",
    "            \"\"\"Get the most recent n log lines.\n",
    "            \n",
    "            Args:\n",
    "                n: Number of recent log lines to retrieve\n",
    "                \n",
    "            Returns:\n",
    "                List of recent log lines\n",
    "            \"\"\"\n",
    "            logs = []\n",
    "            while not self.log_queue.empty() and len(logs) < n\n",
    "        \"Get the most recent n log lines.\n",
    "\n",
    "Args:\n",
    "    n: Number of recent log lines to retrieve\n",
    "    \n",
    "Returns:\n",
    "    List of recent log lines\"\n",
    "    \n",
    "    def get_metrics_from_logs(self) -> dict:\n",
    "            \"\"\"Parse recent logs to extract performance metrics.\n",
    "            \n",
    "            Returns:\n",
    "                Dictionary with metrics like throughput, GPU usage, etc.\n",
    "            \"\"\"\n",
    "            metrics = {\n",
    "                \"prompt_throughput\": 0.0,\n",
    "        \"Parse recent logs to extract performance metrics.\n",
    "\n",
    "Returns:\n",
    "    Dictionary with metrics like throughput, GPU usage, etc.\"\n",
    "    \n",
    "    def tail_logs(self, follow: bool = True, n: int = 10):\n",
    "            \"\"\"Tail the server logs (similar to tail -f).\n",
    "            \n",
    "            Args:\n",
    "                follow: Continue displaying new logs as they arrive\n",
    "                n: Number of initial lines to display\n",
    "            \"\"\"\n",
    "            # Display recent logs\n",
    "            recent = self.get_recent_logs(n)\n",
    "            for line in recent\n",
    "        \"Tail the server logs (similar to tail -f).\n",
    "\n",
    "Args:\n",
    "    follow: Continue displaying new logs as they arrive\n",
    "    n: Number of initial lines to display\"\n",
    "```\n",
    "\n",
    "```python\n",
    "class VoxtralVLLMPlugin:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the Voxtral VLLM plugin with default configuration.\"\"\"\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{type(self).__name__}\")\n",
    "        self.config = {}\n",
    "        self.server: Optional[VLLMServer] = None\n",
    "    \"Mistral Voxtral transcription plugin via vLLM server.\"\n",
    "    \n",
    "    def __init__(self):\n",
    "            \"\"\"Initialize the Voxtral VLLM plugin with default configuration.\"\"\"\n",
    "            self.logger = logging.getLogger(f\"{__name__}.{type(self).__name__}\")\n",
    "            self.config = {}\n",
    "            self.server: Optional[VLLMServer] = None\n",
    "        \"Initialize the Voxtral VLLM plugin with default configuration.\"\n",
    "    \n",
    "    def name(\n",
    "            self\n",
    "        ) -> str:  # Returns the plugin name\n",
    "        \"Get the plugin name identifier.\"\n",
    "    \n",
    "    def version(\n",
    "            self\n",
    "        ) -> str:  # Returns the plugin version\n",
    "        \"Get the plugin version string.\"\n",
    "    \n",
    "    def supported_formats(\n",
    "            self\n",
    "        ) -> List[str]:  # Returns list of supported audio formats\n",
    "        \"Get the list of supported audio file formats.\"\n",
    "    \n",
    "    def get_config_schema(\n",
    "        ) -> Dict[str, Any]:  # Returns the configuration schema dictionary\n",
    "        \"Return configuration schema for Voxtral VLLM.\"\n",
    "    \n",
    "    def get_current_config(\n",
    "            self\n",
    "        ) -> Dict[str, Any]:  # Returns the current configuration dictionary\n",
    "        \"Return current configuration.\"\n",
    "    \n",
    "    def initialize(\n",
    "            self,\n",
    "            config: Optional[Dict[str, Any]] = None  # Configuration dictionary to initialize the plugin\n",
    "        ) -> None\n",
    "        \"Initialize the plugin with configuration.\"\n",
    "    \n",
    "    def execute(\n",
    "            self,\n",
    "            audio: Union[AudioData, str, Path],  # Audio data or path to audio file to transcribe\n",
    "            **kwargs  # Additional arguments to override config\n",
    "        ) -> TranscriptionResult:  # Returns transcription result with text and metadata\n",
    "        \"Transcribe audio using Voxtral via vLLM.\"\n",
    "    \n",
    "    def is_available(\n",
    "            self\n",
    "        ) -> bool:  # Returns True if vLLM and its dependencies are available\n",
    "        \"Check if vLLM and required dependencies are available.\"\n",
    "    \n",
    "    def cleanup(\n",
    "            self\n",
    "        ) -> None\n",
    "        \"Clean up resources.\"\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
