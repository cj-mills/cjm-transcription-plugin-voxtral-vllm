{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64c2732",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "> Metadata introspection for the Voxtral VLLM plugin used by cjm-ctl to generate the registration manifest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d7bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acdb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import sys\n",
    "from typing import Any, Dict\n",
    "from cjm_transcription_plugin_voxtral_vllm import __version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e9f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_plugin_metadata() -> Dict[str, Any]: # Plugin metadata for manifest generation\n",
    "    \"\"\"Return metadata required to register this plugin with the PluginManager.\"\"\"\n",
    "    # Fallback base path (current behavior for backward compatibility)\n",
    "    base_path = os.path.dirname(os.path.dirname(sys.executable))\n",
    "    \n",
    "    # Use CJM config if available, else fallback to env-relative paths\n",
    "    cjm_data_dir = os.environ.get(\"CJM_DATA_DIR\")\n",
    "    cjm_models_dir = os.environ.get(\"CJM_MODELS_DIR\")\n",
    "    \n",
    "    # Plugin data directory\n",
    "    plugin_name = \"cjm-transcription-plugin-voxtral-vllm\"\n",
    "    if cjm_data_dir:\n",
    "        data_dir = os.path.join(cjm_data_dir, plugin_name)\n",
    "    else:\n",
    "        data_dir = os.path.join(base_path, \"data\")\n",
    "    \n",
    "    db_path = os.path.join(data_dir, \"voxtral_vllm_transcriptions.db\")\n",
    "    \n",
    "    # Ensure data directory exists\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    # HuggingFace cache: use models_dir if configured\n",
    "    if cjm_models_dir:\n",
    "        hf_home = os.path.join(cjm_models_dir, \"huggingface\")\n",
    "    else:\n",
    "        hf_home = os.path.join(base_path, \".cache\", \"huggingface\")\n",
    "\n",
    "    return {\n",
    "        \"name\": plugin_name,\n",
    "        \"version\": __version__,\n",
    "        \"type\": \"transcription\",\n",
    "        \"category\": \"transcription\",\n",
    "        \"interface\": \"cjm_transcription_plugin_system.plugin_interface.TranscriptionPlugin\",\n",
    "        \n",
    "        \"module\": \"cjm_transcription_plugin_voxtral_vllm.plugin\",\n",
    "        \"class\": \"VoxtralVLLMPlugin\",\n",
    "        \n",
    "        # Critical: The absolute path to THIS environment's python\n",
    "        \"python_path\": sys.executable,\n",
    "        \n",
    "        \"db_path\": db_path,\n",
    "        \n",
    "        # Voxtral via vLLM requires significant GPU resources\n",
    "        # Mini: ~8GB VRAM, Small: ~48GB VRAM\n",
    "        \"resources\": {\n",
    "            \"requires_gpu\": True,\n",
    "            \"min_gpu_vram_mb\": 8192,\n",
    "            \"recommended_gpu_vram_mb\": 16384,\n",
    "            \"min_system_ram_mb\": 16384\n",
    "        },\n",
    "        \n",
    "        \"env_vars\": {\n",
    "            \"CUDA_VISIBLE_DEVICES\": \"0\",\n",
    "            \"VLLM_ATTENTION_BACKEND\": \"FLASHINFER\",\n",
    "            \"HF_HOME\": hf_home\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21850c5c",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb4b1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"cjm-transcription-plugin-voxtral-vllm\",\n",
      "  \"version\": \"0.0.13\",\n",
      "  \"type\": \"transcription\",\n",
      "  \"category\": \"transcription\",\n",
      "  \"interface\": \"cjm_transcription_plugin_system.plugin_interface.TranscriptionPlugin\",\n",
      "  \"module\": \"cjm_transcription_plugin_voxtral_vllm.plugin\",\n",
      "  \"class\": \"VoxtralVLLMPlugin\",\n",
      "  \"python_path\": \"/home/innom-dt/miniforge3/envs/cjm-transcription-plugin-voxtral-vllm/bin/python3.12\",\n",
      "  \"db_path\": \"/home/innom-dt/miniforge3/envs/cjm-transcription-plugin-voxtral-vllm/data/voxtral_vllm_transcriptions.db\",\n",
      "  \"resources\": {\n",
      "    \"requires_gpu\": true,\n",
      "    \"min_gpu_vram_mb\": 8192,\n",
      "    \"recommended_gpu_vram_mb\": 16384,\n",
      "    \"min_system_ram_mb\": 16384\n",
      "  },\n",
      "  \"env_vars\": {\n",
      "    \"CUDA_VISIBLE_DEVICES\": \"0\",\n",
      "    \"VLLM_ATTENTION_BACKEND\": \"FLASHINFER\",\n",
      "    \"HF_HOME\": \"/home/innom-dt/miniforge3/envs/cjm-transcription-plugin-voxtral-vllm/.cache/huggingface\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "metadata = get_plugin_metadata()\n",
    "print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
